{
  "project": "test",
  "name": "integer_in_pk",
  "checkId": "L003",
  "timestamptz": "2019-09-04 18:19:44.0+0000",
  "dependencies": {
    "null": "null"
  },
  "last_nodes_json": {
    "hosts": {
      "postgres.test1.node": {
        "internal_alias": "node1",
        "index": "1",
        "role": "standby",
        "role_change_detected_at": "never"
      },
      "postgres.test2.node": {
        "internal_alias": "node2",
        "index": "2",
        "role": "standby",
        "role_change_detected_at": "never"
      },
      "postgres.test3.node": {
        "internal_alias": "node3",
        "index": "3",
        "role": "master",
        "role_change_detected_at": "never"
      }
    },
    "last_check": {
      "epoch": "1",
      "timestamptz": "2019-09-04 18:19:44.0+0000",
      "dir": "1_2019_09_04T18_19_21_+0000"
    }
  },
  "database": "dbname",
  "results": {
    "postgres.test3.node": {
      "data": {
        "tables": {
          "orders": {
            "table": "test_schema.orders",
            "pk": "id",
            "type": "int4",
            "current_max_value": 800000000,
            "capacity_used_percent": 37.25
          },
          "orders_A": {
            "table": "test_schema.\"orders_A\"",
            "pk": "id",
            "type": "int4",
            "current_max_value": 300000000,
            "capacity_used_percent": 13.97
          }
        },
        "min_table_size_bytes": 0
      },
      "nodes.json": {
        "hosts": {
          "postgres.test1.node": {
            "internal_alias": "node1",
            "index": "1",
            "role": "standby",
            "role_change_detected_at": "never"
          },
          "postgres.test2.node": {
            "internal_alias": "node2",
            "index": "2",
            "role": "standby",
            "role_change_detected_at": "never"
          },
          "postgres.test3.node": {
            "internal_alias": "node3",
            "index": "3",
            "role": "master",
            "role_change_detected_at": "never"
          }
        },
        "last_check": {
          "epoch": "1",
          "timestamptz": "2019-09-04 18:19:44.0+0000",
          "dir": "1_2019_09_04T18_19_21_+0000"
        }
      }
    }
  },
  "processed": true,
  "conclusions": [
    {
      "Id": "L003_HIGH_RISKS",
      "Message": "[P1] High risks of out-of-range errors for an integer column. The columns listed below, being part of a primary key, have high risks to reach 100% of the integer capacity (`2^31-1`, or `2147483647` for `int4` columns, and `2^15-1`, or `32767` for `int2` columns; see [the documentation](https://www.postgresql.org/docs/current/datatype-numeric.html). If it happens, INSERTs of new rows will not be possible (unless they use some non-incremental values, such as some negative values) and fixing it will require a long downtime. 2 such columns are found:\n    - `test_schema.orders`: reached value 800000000, or 37.25% of `int4` capacity\n    - `test_schema.\"orders_A\"`: reached value 300000000, or 13.97% of `int4` capacity\n"
    }
  ],
  "recommendations": [
    {
      "Id": "L003_HIGH_RISKS",
      "Message": "[P1] High risks of out-of-range errors for an integer column. Consider using `int8` in all PK columns,  always. To convert existing columns to `int8`, consider the  following approaches:\n    1. Blocking `ALTER TABLE .. ALTER COLUMN`: a straightforward solution requiring significant downtime (a maintenance window).\n    1. \"New column\": create a new column, update it in batches (running not longer than a few seconds, to avoid blocking issues), and then switch to using it, redefining all the constraints. Notice, that to redefine a primary key constraint, `ALTER TABLE .. ALTER COLUMN .. SET NOT NULL` will be needed. It is a blocking operation in all Postgres versions up to 12 (where it might be lightweight if a proper `CHECK` constraint is defined first; such constraint can be defined in a non-blocking way). Since Postgres 11, it is possible to use a trick: when adding a column, use `DEFAULT` with `NOT NULL`, it will be a non-blocking operation. For all Postgres versions prior to 11, a specific downtime (maintenance window) will be needed anyway.\n    1. \"New table\": create a new table with the same schema as the existing one, capture all ongoing changes to an additional \"log\" table, copy existing data from the old table to the new one, and switch. This method, as the previous one, is non-trivial and requires careful development and testing under load (consider using [Nancy](https://gitlab.com/postgres-ai/nancy) for database experiments developing this solution). This approach is non-blocking regardless of Postgres version, but it requires significantly more efforts to implement."
    }
  ],
  "p1": true,
  "p2": false,
  "p3": false
}